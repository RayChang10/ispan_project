#!/usr/bin/env python3
"""
Fast Agent æ©‹æ¥æ¨¡çµ„
ç”¨æ–¼åœ¨ virtual_interviewer ä¸­èª¿ç”¨ Fast Agent åŠŸèƒ½
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

try:
    from tools.answer_analyzer import answer_analyzer
    from tools.question_manager import question_manager

    TOOLS_AVAILABLE = True
except ImportError:
    TOOLS_AVAILABLE = False
    print("âš ï¸ tools æ¨¡çµ„ä¸å¯ç”¨")

# OpenAI ç›¸é—œå°å…¥
try:
    import openai
    from openai import OpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI æ¨¡çµ„ä¸å¯ç”¨")


def call_openai_for_analysis(prompt: str, max_tokens: int = 1500):
    """èª¿ç”¨ OpenAI API é€²è¡Œåˆ†æ"""
    try:
        if not OPENAI_AVAILABLE:
            raise Exception("OpenAI æ¨¡çµ„ä¸å¯ç”¨")

        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise Exception("OPENAI_API_KEY æœªè¨­å®š")

        client = OpenAI(api_key=api_key)

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "æ‚¨æ˜¯ä¸€å€‹å°ˆæ¥­çš„é¢è©¦å®˜å’Œè·æ¶¯é¡§å•ï¼Œæ“…é•·åˆ†æè‡ªæˆ‘ä»‹ç´¹ä¸¦æä¾›å…·é«”çš„æ”¹é€²å»ºè­°ã€‚è«‹æ ¹æ“šè¦æ±‚åˆ†æç”¨æˆ¶çš„è‡ªæˆ‘ä»‹ç´¹ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=max_tokens,
        )

        content = response.choices[0].message.content
        return content.strip() if content else ""

    except Exception as e:
        print(f"âŒ OpenAI API èª¿ç”¨å¤±æ•—: {e}")
        raise e


def get_question():
    """ç²å–éš¨æ©Ÿé¢è©¦å•é¡Œ - å„ªå…ˆä½¿ç”¨ MCP å·¥å…·"""
    try:
        # å„ªå…ˆä½¿ç”¨ MCP å·¥å…·
        from server import get_random_question as mcp_get_random_question

        result = mcp_get_random_question()
        if result.get("status") == "success":
            # è¿”å›å®Œæ•´çš„æ•¸æ“šçµæ§‹ï¼ŒåŒ…å«æ¨™æº–ç­”æ¡ˆ
            return {
                "success": True,
                "result": f"""
ğŸ¯ MCP å·¥å…·é¢è©¦å•é¡Œ

å•é¡Œï¼š{result['question']}
é¡åˆ¥ï¼š{result['category']}
é›£åº¦ï¼š{result['difficulty']}
ä¾†æºï¼š{result['source']}

è«‹å›ç­”é€™å€‹å•é¡Œï¼Œç„¶å¾Œä½¿ç”¨ analyze_answer åŠŸèƒ½ä¾†åˆ†ææ‚¨çš„å›ç­”ã€‚
                """,
                "question_data": {
                    "question": result["question"],
                    "standard_answer": result["standard_answer"],
                    "category": result["category"],
                    "difficulty": result["difficulty"],
                    "source": result["source"],
                },
            }
        else:
            return {
                "success": False,
                "error": f"MCP å·¥å…·ç²å–å•é¡Œå¤±æ•—ï¼š{result.get('message', 'æœªçŸ¥éŒ¯èª¤')}",
            }
    except ImportError:
        # å›é€€åˆ°åŸå§‹å·¥å…·
        if not TOOLS_AVAILABLE:
            return {"success": False, "error": "å·¥å…·æ¨¡çµ„ä¸å¯ç”¨ï¼Œç„¡æ³•ç²å–å•é¡Œ"}

        try:
            question_data = question_manager.get_random_question()
            category = _categorize_question(question_data["question"])
            difficulty = _assess_difficulty(question_data["question"])

            return {
                "success": True,
                "result": f"""
ğŸ¯ é¢è©¦å•é¡Œ

å•é¡Œï¼š{question_data['question']}
é¡åˆ¥ï¼š{category}
é›£åº¦ï¼š{difficulty}
ä¾†æºï¼š{question_data['source']}

è«‹å›ç­”é€™å€‹å•é¡Œï¼Œç„¶å¾Œä½¿ç”¨ analyze_answer åŠŸèƒ½ä¾†åˆ†ææ‚¨çš„å›ç­”ã€‚
                """,
                "question_data": {
                    "question": question_data["question"],
                    "standard_answer": question_data.get(
                        "standard_answer", "æ¨™æº–ç­”æ¡ˆæœªæä¾›"
                    ),
                    "category": category,
                    "difficulty": difficulty,
                    "source": question_data["source"],
                },
            }
        except Exception as e:
            return {"success": False, "error": f"ç²å–å•é¡Œå¤±æ•—ï¼š{str(e)}"}
    except Exception as e:
        return {"success": False, "error": f"MCP å·¥å…·éŒ¯èª¤ï¼š{str(e)}"}


# å…¨å±€è®Šæ•¸ä¾†å„²å­˜è‡ªæˆ‘ä»‹ç´¹å…§å®¹
_user_intro_content = {}


def intro_collector(user_message: str = ""):
    """æ”¶é›†ç”¨æˆ¶è‡ªæˆ‘ä»‹ç´¹å…§å®¹"""
    try:
        print(f"ğŸ“ æ”¶é›†è‡ªæˆ‘ä»‹ç´¹å…§å®¹: {user_message}")

        user_id = "default_user"  # å¯ä»¥æ ¹æ“šéœ€è¦èª¿æ•´

        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ”¶é›†ï¼Œåˆå§‹åŒ–
        if user_id not in _user_intro_content:
            _user_intro_content[user_id] = []

        # æ·»åŠ æ–°çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹
        _user_intro_content[user_id].append(user_message)

        # è¿”å›ç•¶å‰å·²æ”¶é›†çš„å…§å®¹
        all_content = " ".join(_user_intro_content[user_id])

        return {
            "success": True,
            "result": f"âœ… å·²è¨˜éŒ„æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹",
            "message": "è‡ªæˆ‘ä»‹ç´¹å…§å®¹å·²æˆåŠŸè¨˜éŒ„",
            "collected_content": all_content,
        }
    except Exception as e:
        return {"success": False, "error": f"è¨˜éŒ„è‡ªæˆ‘ä»‹ç´¹å¤±æ•—: {str(e)}"}


def get_collected_intro(user_id: str = "default_user"):
    """ç²å–å·²æ”¶é›†çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹"""
    if user_id in _user_intro_content and _user_intro_content[user_id]:
        return " ".join(_user_intro_content[user_id])
    return ""


def clear_collected_intro(user_id: str = "default_user"):
    """æ¸…é™¤å·²æ”¶é›†çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹"""
    if user_id in _user_intro_content:
        _user_intro_content[user_id] = []


def analyze_answer(
    user_answer: str = "", question: str = "", standard_answer: str = ""
):
    """åˆ†æç”¨æˆ¶å›ç­” - å„ªå…ˆä½¿ç”¨ MCP å·¥å…·"""

    # åªåœ¨æ˜ç¢ºçš„è‡ªæˆ‘ä»‹ç´¹æƒ…æ³ä¸‹æ‰è¿”å›è‡ªæˆ‘ä»‹ç´¹å›æ‡‰
    # ç§»é™¤éæ–¼å¯¬æ³›çš„é—œéµå­—åŒ¹é…ï¼Œé¿å…èª¤åˆ¤é¢è©¦å›ç­”
    lower_answer = user_answer.lower()
    if (
        any(
            phrase in lower_answer
            for phrase in [
                "æˆ‘å«",
                "æˆ‘çš„åå­—æ˜¯",
                "æˆ‘çš„åå­—å«",
                "è‡ªæˆ‘ä»‹ç´¹ä¸€ä¸‹",
                "è®“æˆ‘è‡ªæˆ‘ä»‹ç´¹",
            ]
        )
        and len(user_answer) < 50
    ):  # åªæœ‰çŸ­å¥ä¸”æ˜ç¢ºçš„è‡ªæˆ‘ä»‹ç´¹æ‰è§¸ç™¼
        return {
            "success": True,
            "result": f"""
ğŸ‘‹ å¾ˆé«˜èˆˆèªè­˜æ‚¨ï¼

æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹ï¼š{user_answer}

é€™æ˜¯ä¸€å€‹å¾ˆå¥½çš„é–‹å§‹ï¼ç¾åœ¨æˆ‘å€‘å¯ä»¥é–‹å§‹æ­£å¼çš„é¢è©¦æµç¨‹ã€‚

è«‹è¼¸å…¥ã€Œé–‹å§‹é¢è©¦ã€æˆ–ã€Œå•é¡Œã€ä¾†ç²å–é¢è©¦å•é¡Œã€‚
            """,
        }

    try:
        # å„ªå…ˆä½¿ç”¨ MCP å·¥å…·
        from server import analyze_user_answer as mcp_analyze_user_answer

        result = mcp_analyze_user_answer(
            user_answer=user_answer, question=question, standard_answer=standard_answer
        )

        if result.get("status") == "success":
            response = f"""
ğŸ“Š MCP å·¥å…·åˆ†æçµæœ

è©•åˆ†ï¼š{result.get('score', 'N/A')}/100 ({result.get('grade', 'N/A')})
ç›¸ä¼¼åº¦ï¼š{result.get('similarity', 'N/A')}
åé¥‹ï¼š{result.get('feedback', 'ç„¡åé¥‹')}

æ¨™æº–ç­”æ¡ˆï¼š{result.get('standard_answer', standard_answer)}
            """

            if result.get("differences"):
                response += "\nğŸ” å…·é«”å·®ç•°ï¼š\n"
                for diff in result["differences"]:
                    response += f"  â€¢ {diff}\n"

            return {"success": True, "result": response}
        else:
            return {
                "success": False,
                "error": f"MCP å·¥å…·åˆ†æå¤±æ•—ï¼š{result.get('message', 'æœªçŸ¥éŒ¯èª¤')}",
            }
    except ImportError:
        # å›é€€åˆ°åŸå§‹å·¥å…·
        if not TOOLS_AVAILABLE:
            return {"success": False, "error": "å·¥å…·æ¨¡çµ„ä¸å¯ç”¨ï¼Œç„¡æ³•åˆ†æå›ç­”"}

        try:
            # å¦‚æœæ²’æœ‰æä¾›æ¨™æº–ç­”æ¡ˆï¼Œå˜—è©¦å¾å•é¡Œç²å–
            if not standard_answer:
                question_data = question_manager.get_random_question()
                standard_answer = question_data.get("standard_answer", "æ¨™æº–ç­”æ¡ˆæœªæä¾›")

            # ä½¿ç”¨ç­”æ¡ˆåˆ†æå™¨åˆ†æ
            analysis = answer_analyzer.analyze_answer(user_answer, standard_answer)

            response = f"""
ğŸ“Š åˆ†æçµæœ

è©•åˆ†ï¼š{analysis['score']}/100 ({analysis['grade']})
ç›¸ä¼¼åº¦ï¼š{analysis['similarity']:.1%}
åé¥‹ï¼š{analysis['feedback']}

æ¨™æº–ç­”æ¡ˆï¼š{standard_answer}
            """

            if analysis["differences"]:
                response += "\nğŸ” å…·é«”å·®ç•°ï¼š\n"
                for diff in analysis["differences"]:
                    response += f"  â€¢ {diff}\n"

            return {"success": True, "result": response}

        except Exception as e:
            return {"success": False, "error": f"åˆ†æå¤±æ•—ï¼š{str(e)}"}
    except Exception as e:
        return f"MCP å·¥å…·éŒ¯èª¤ï¼š{str(e)}"


def get_standard_answer(question: str = ""):
    """ç²å–æ¨™æº–ç­”æ¡ˆ - å„ªå…ˆä½¿ç”¨ MCP å·¥å…·"""
    try:
        # å„ªå…ˆä½¿ç”¨ MCP å·¥å…·
        from server import get_standard_answer as mcp_get_standard_answer

        result = mcp_get_standard_answer(question=question)
        if result.get("status") == "success":
            response = f"""
âœ… MCP å·¥å…·æ¨™æº–ç­”æ¡ˆ

å•é¡Œï¼š{result['question']}
æ¨™æº–ç­”æ¡ˆï¼š{result['standard_answer']}
ä¾†æºï¼š{result['source']}
            """
            return response
        else:
            return f"MCP å·¥å…·ç²å–æ¨™æº–ç­”æ¡ˆå¤±æ•—ï¼š{result.get('message', 'æœªçŸ¥éŒ¯èª¤')}"
    except ImportError:
        # å›é€€åˆ°åŸå§‹å·¥å…·
        if not TOOLS_AVAILABLE:
            return "å·¥å…·æ¨¡çµ„ä¸å¯ç”¨ï¼Œç„¡æ³•ç²å–æ¨™æº–ç­”æ¡ˆ"

        try:
            question_data = question_manager.get_random_question()

            response = f"""
âœ… æ¨™æº–ç­”æ¡ˆ

å•é¡Œï¼š{question_data['question']}
æ¨™æº–ç­”æ¡ˆï¼š{question_data['standard_answer']}
ä¾†æºï¼š{question_data['source']}
            """
            return response
        except Exception as e:
            return f"ç²å–æ¨™æº–ç­”æ¡ˆå¤±æ•—ï¼š{str(e)}"
    except Exception as e:
        return f"MCP å·¥å…·éŒ¯èª¤ï¼š{str(e)}"


def start_interview():
    """é–‹å§‹äº’å‹•å¼é¢è©¦ - å„ªå…ˆä½¿ç”¨ MCP å·¥å…·"""
    try:
        # å„ªå…ˆä½¿ç”¨ MCP å·¥å…·
        from server import conduct_interview as mcp_conduct_interview

        result = mcp_conduct_interview()
        if result.get("status") == "success":
            response = f"""
ğŸ¤– MCP å·¥å…·æ™ºèƒ½é¢è©¦ç³»çµ±ï¼

============================================================
ğŸ¯ é¢è©¦ç³»çµ±
============================================================
{result.get('message', 'é¢è©¦å·²é–‹å§‹')}

è«‹å›ç­”å•é¡Œï¼Œç„¶å¾Œä½¿ç”¨ analyze_answer åŠŸèƒ½ä¾†åˆ†ææ‚¨çš„å›ç­”ã€‚
            """
            return response
        else:
            return f"MCP å·¥å…·é¢è©¦å¤±æ•—ï¼š{result.get('message', 'æœªçŸ¥éŒ¯èª¤')}"
    except ImportError:
        # å›é€€åˆ°åŸå§‹å·¥å…·
        if not TOOLS_AVAILABLE:
            return "å·¥å…·æ¨¡çµ„ä¸å¯ç”¨ï¼Œç„¡æ³•é–‹å§‹é¢è©¦"

        try:
            question_data = question_manager.get_random_question()
            category = _categorize_question(question_data["question"])
            difficulty = _assess_difficulty(question_data["question"])

            response = f"""
ğŸ¤– æ­¡è¿ä½¿ç”¨æ™ºèƒ½é¢è©¦ç³»çµ±ï¼

============================================================
ğŸ¯ é¢è©¦å•é¡Œ
============================================================
å•é¡Œï¼š{question_data['question']}
é¡åˆ¥ï¼š{category}
é›£åº¦ï¼š{difficulty}
ä¾†æºï¼š{question_data['source']}

è«‹å›ç­”é€™å€‹å•é¡Œï¼Œç„¶å¾Œä½¿ç”¨ analyze_answer åŠŸèƒ½ä¾†åˆ†ææ‚¨çš„å›ç­”ã€‚
            """
            return response
        except Exception as e:
            return f"é–‹å§‹é¢è©¦å¤±æ•—ï¼š{str(e)}"
    except Exception as e:
        return f"MCP å·¥å…·éŒ¯èª¤ï¼š{str(e)}"


def analyze_intro(user_message: str = ""):
    """åˆ†æç”¨æˆ¶è‡ªæˆ‘ä»‹ç´¹ - ä½¿ç”¨ LLM é€²è¡Œæ™ºèƒ½åˆ†æ"""
    try:
        print(f"ğŸ“Š åˆ†æè‡ªæˆ‘ä»‹ç´¹å…§å®¹: {user_message}")

        # å„ªå…ˆä½¿ç”¨ LLM åˆ†æ
        try:
            return _llm_analyze_intro(user_message)
        except Exception as llm_error:
            print(f"âš ï¸ LLM åˆ†æå¤±æ•—ï¼Œå›é€€åˆ°é—œéµå­—åˆ†æ: {llm_error}")
            return _fallback_keyword_analysis(user_message)

    except Exception as e:
        return {"success": False, "error": f"åˆ†æè‡ªæˆ‘ä»‹ç´¹å¤±æ•—: {str(e)}"}


def _llm_analyze_intro(user_message: str):
    """ä½¿ç”¨ LLM é€²è¡Œè‡ªæˆ‘ä»‹ç´¹åˆ†æ"""
    analysis_prompt = f"""
è«‹åˆ†æä»¥ä¸‹è‡ªæˆ‘ä»‹ç´¹å…§å®¹ï¼ŒæŒ‰ç…§6å€‹æ¨™æº–é€²è¡Œå°ˆæ¥­è©•ä¼°ï¼š

**è‡ªæˆ‘ä»‹ç´¹å…§å®¹**ï¼š
{user_message}

**è©•ä¼°æ¨™æº–**ï¼š
1. é–‹å ´ç°¡ä»‹ï¼šæ˜¯å¦åŒ…å«èº«ä»½ã€å°ˆæ¥­å®šä½ã€ç¶“é©—å¹´æ•¸ç­‰åŸºæœ¬ä¿¡æ¯
2. å­¸ç¶“æ­·æ¦‚è¿°ï¼šæ˜¯å¦åŒ…å«å­¸æ­·èƒŒæ™¯ã€å·¥ä½œç¶“æ­·ã€ç›¸é—œç¶“é©—ç­‰
3. æ ¸å¿ƒæŠ€èƒ½èˆ‡å¼·é …ï¼šæ˜¯å¦åŒ…å«æŠ€è¡“æŠ€èƒ½ã€ç¨‹å¼èªè¨€ã€å°ˆæ¥­èƒ½åŠ›ç­‰
4. ä»£è¡¨æˆæœï¼šæ˜¯å¦åŒ…å«å…·é«”é …ç›®ã€æˆå°±ã€æ•¸æ“šæˆ–å½±éŸ¿åŠ›ç­‰
5. èˆ‡è·ç¼ºçš„é€£çµï¼šæ˜¯å¦è¡¨é”å°è·ä½çš„ç†è§£ã€åŒ¹é…åº¦æˆ–å‹•æ©Ÿç­‰
6. çµèªèˆ‡æœŸå¾…ï¼šæ˜¯å¦åŒ…å«æ„Ÿè¬ã€æœŸå¾…ã€åˆä½œæ„é¡˜ç­‰çµèª

è«‹ä»¥ JSON æ ¼å¼è¿”å›åˆ†æçµæœï¼Œç¢ºä¿ JSON æ ¼å¼æ­£ç¢ºï¼š
{{
    "analysis": [
        {{"standard": "1. é–‹å ´ç°¡ä»‹", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}},
        {{"standard": "2. å­¸ç¶“æ­·æ¦‚è¿°", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}},
        {{"standard": "3. æ ¸å¿ƒæŠ€èƒ½èˆ‡å¼·é …", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}},
        {{"standard": "4. ä»£è¡¨æˆæœ", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}},
        {{"standard": "5. èˆ‡è·ç¼ºçš„é€£çµ", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}},
        {{"standard": "6. çµèªèˆ‡æœŸå¾…", "status": "âœ… å·²åŒ…å«" æˆ– "âŒ ç¼ºå°‘", "content": "ç°¡çŸ­èªªæ˜æ‰¾åˆ°çš„å…§å®¹æˆ–ç¼ºå¤±åŸå› ", "score": 1-10}}
    ],
    "overall_score": "æ•´é«”è©•åˆ† (1-10)",
    "strengths": ["å„ªé»1", "å„ªé»2"],
    "suggestions": ["å…·é«”æ”¹é€²å»ºè­°1", "å…·é«”æ”¹é€²å»ºè­°2"]
}}

è«‹ç¢ºä¿è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¡å¤–çš„æ–‡å­—èªªæ˜ã€‚
"""

    # èª¿ç”¨ LLM
    llm_response = call_openai_for_analysis(analysis_prompt, max_tokens=1500)

    # è§£æ JSON å›æ‡‰
    try:
        # å˜—è©¦æå– JSON éƒ¨åˆ†
        json_start = llm_response.find("{")
        json_end = llm_response.rfind("}") + 1
        if json_start != -1 and json_end > json_start:
            json_content = llm_response[json_start:json_end]
        else:
            json_content = llm_response

        analysis_data = json.loads(json_content)
    except json.JSONDecodeError as e:
        print(f"âš ï¸ JSON è§£æå¤±æ•—: {e}")
        print(f"LLM å›æ‡‰: {llm_response}")
        # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œå›é€€åˆ°é—œéµå­—åˆ†æ
        raise Exception(f"LLM è¿”å›æ ¼å¼éŒ¯èª¤: {e}")

    # ç”Ÿæˆåˆ†æå ±å‘Š
    report = f"""
ğŸ“Š **LLM æ™ºèƒ½è‡ªæˆ‘ä»‹ç´¹åˆ†æå ±å‘Š**

**æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹**ï¼š
{user_message}

**è©•ä¼°çµæœ**ï¼š
"""

    for item in analysis_data["analysis"]:
        report += f"{item['status']} **{item['standard']}** (è©•åˆ†: {item['score']}/10): {item['content']}\n"

    # è™•ç†æ•´é«”è©•åˆ†ï¼Œç¢ºä¿é¡¯ç¤ºå…·é«”æ•¸å­—
    overall_score = analysis_data.get("overall_score", "0")
    if isinstance(overall_score, str):
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå˜—è©¦æå–æ•¸å­—
        import re

        score_match = re.search(r"(\d+(?:\.\d+)?)", str(overall_score))
        if score_match:
            overall_score = score_match.group(1)
        else:
            # å¦‚æœç„¡æ³•æå–ï¼Œè¨ˆç®—å¹³å‡åˆ†
            scores = [
                item.get("score", 0) for item in analysis_data.get("analysis", [])
            ]
            if scores:
                overall_score = round(sum(scores) / len(scores), 1)
            else:
                overall_score = "0"

    report += f"""
**æ•´é«”è©•åˆ†**ï¼š{overall_score}/10

**æ‚¨çš„å„ªé»**ï¼š
"""

    for strength in analysis_data.get("strengths", []):
        report += f"â€¢ {strength}\n"

    report += f"""
**æ”¹é€²å»ºè­°**ï¼š
"""

    for suggestion in analysis_data.get("suggestions", []):
        report += f"â€¢ {suggestion}\n"

    report += f"""
**åƒè€ƒç¯„ä¾‹çµæ§‹**ï¼š
1. é–‹å ´ç°¡ä»‹ï¼šã€Œæ‚¨å¥½ï¼Œæˆ‘æ˜¯XXXï¼Œä¸€ä½æœ‰Xå¹´ç¶“é©—çš„XXXã€
2. å­¸ç¶“æ­·ï¼šã€Œæˆ‘ç•¢æ¥­æ–¼XXXï¼Œåœ¨XXXå…¬å¸æ“”ä»»XXXã€  
3. æŠ€èƒ½å¼·é …ï¼šã€Œæˆ‘ç†Ÿæ‚‰XXXæŠ€è¡“ï¼Œæ“…é•·XXXã€
4. ä»£è¡¨æˆæœï¼šã€Œæˆ‘æ›¾ç¶“XXXï¼Œæå‡äº†X%æ•ˆç‡ã€
5. è·ç¼ºé€£çµï¼šã€Œæˆ‘èªç‚ºé€™å€‹è·ä½èˆ‡æˆ‘çš„XXXç¶“é©—åŒ¹é…ã€
6. çµèªæœŸå¾…ï¼šã€ŒæœŸå¾…èƒ½ç‚ºè²´å…¬å¸è²¢ç»æˆ‘çš„å°ˆé•·ã€
    """

    return {
        "success": True,
        "result": report,
        "message": "LLM æ™ºèƒ½åˆ†æå®Œæˆ",
        "analysis_data": analysis_data,
    }


def _fallback_keyword_analysis(user_message: str):
    """å›é€€çš„é—œéµå­—åˆ†ææ–¹æ³•"""
    try:
        print("ğŸ”„ ä½¿ç”¨é—œéµå­—åˆ†æä½œç‚ºå›é€€æ–¹æ¡ˆ")

        # æ”¹é€²çš„é—œéµå­—åˆ†æé‚è¼¯
        standards = {
            "1. é–‹å ´ç°¡ä»‹": [
                "æˆ‘æ˜¯",
                "æˆ‘å«",
                "èº«ä»½",
                "å°ˆæ¥­å®šä½",
                "ç¶“é©—",
                "å¹´æ•¸",
                "é ˜åŸŸ",
                "å·¥ç¨‹å¸«",
                "é–‹ç™¼è€…",
                "ç¨‹å¼è¨­è¨ˆå¸«",
                "è³‡æ·±",
                "åˆç´š",
                "ä¸­ç´š",
            ],
            "2. å­¸ç¶“æ­·æ¦‚è¿°": [
                "å­¸æ­·",
                "ç•¢æ¥­",
                "å¤§å­¸",
                "ç¢©å£«",
                "åšå£«",
                "å·¥ä½œç¶“æ­·",
                "ä»»è·",
                "æ“”ä»»",
                "ç›¸é—œç¶“é©—",
                "è·ä½",
                "å…¬å¸",
                "æœå‹™",
                "å·¥ä½œ",
                "ç¶“æ­·",
                "èƒŒæ™¯",
            ],
            "3. æ ¸å¿ƒæŠ€èƒ½èˆ‡å¼·é …": [
                "æŠ€è¡“",
                "æŠ€èƒ½",
                "è»ŸæŠ€èƒ½",
                "å°ˆé•·",
                "å„ªå‹¢",
                "æ“…é•·",
                "ç†Ÿæ‚‰",
                "æœƒ",
                "python",
                "java",
                "javascript",
                "react",
                "vue",
                "angular",
                "node",
                "django",
                "flask",
                "spring",
                "mysql",
                "postgresql",
                "mongodb",
                "docker",
                "kubernetes",
                "aws",
                "azure",
                "linux",
                "git",
                "html",
                "css",
                "typescript",
                "php",
                "c++",
                "golang",
                "rust",
                "ç¨‹å¼èªè¨€",
                "æ¡†æ¶",
                "è³‡æ–™åº«",
                "é›²ç«¯",
                "æ©Ÿå™¨å­¸ç¿’",
                "ai",
                "devops",
            ],
            "4. ä»£è¡¨æˆæœ": [
                "å°ˆæ¡ˆ",
                "é …ç›®",
                "é–‹ç™¼",
                "å»ºç«‹",
                "å®Œæˆ",
                "é”æˆ",
                "æå‡",
                "æ”¹å–„",
                "å…·é«”æˆæœ",
                "æ•¸æ“š",
                "å½±éŸ¿åŠ›",
                "åƒ¹å€¼",
                "æˆå°±",
                "è²¢ç»",
                "æ•ˆç‡",
                "é™ä½",
                "å¢åŠ ",
                "å„ªåŒ–",
                "å¯¦ä½œ",
                "å»ºç½®",
            ],
            "5. èˆ‡è·ç¼ºçš„é€£çµ": [
                "è·ä½",
                "å·¥ä½œ",
                "å…¬å¸",
                "åœ˜éšŠ",
                "åŒ¹é…",
                "é©åˆ",
                "ç›®æ¨™",
                "å‹•æ©Ÿ",
                "å¸Œæœ›",
                "æƒ³è¦",
                "è²¢ç»",
                "åŠ å…¥",
                "ç™¼å±•",
                "æˆé•·",
                "å­¸ç¿’",
            ],
            "6. çµèªèˆ‡æœŸå¾…": [
                "æœŸå¾…",
                "å¸Œæœ›",
                "æ„Ÿè¬",
                "è¬è¬",
                "åˆä½œ",
                "å­¸ç¿’",
                "æˆé•·",
                "è²¢ç»",
                "æ©Ÿæœƒ",
                "æœªä¾†",
                "ç™¼å±•",
                "æ…‹åº¦",
                "æ„é¡˜",
                "è«‹å¤šæŒ‡æ•™",
            ],
        }

        # æ”¹é€²çš„åŒ¹é…é‚è¼¯
        analysis_result = []
        missing_parts = []
        suggestions = []
        lower_message = user_message.lower()

        for standard, keywords in standards.items():
            found_keywords = []
            for keyword in keywords:
                # æ›´éˆæ´»çš„åŒ¹é…é‚è¼¯
                if keyword.lower() in lower_message:
                    found_keywords.append(keyword)
                # ç‰¹åˆ¥è™•ç†æŠ€èƒ½ç›¸é—œçš„åŒ¹é…
                elif standard == "3. æ ¸å¿ƒæŠ€èƒ½èˆ‡å¼·é …" and keyword in [
                    "æœƒ",
                    "ç†Ÿæ‚‰",
                    "æ“…é•·",
                ]:
                    # æª¢æŸ¥æ˜¯å¦æœ‰æŠ€è¡“ç›¸é—œè©å½™
                    tech_keywords = [
                        "python",
                        "java",
                        "javascript",
                        "react",
                        "vue",
                        "angular",
                        "node",
                        "django",
                        "flask",
                        "spring",
                        "mysql",
                        "postgresql",
                        "mongodb",
                        "docker",
                        "kubernetes",
                        "aws",
                        "azure",
                        "linux",
                        "git",
                        "html",
                        "css",
                        "typescript",
                        "php",
                        "c++",
                        "golang",
                        "rust",
                    ]
                    if any(tech in lower_message for tech in tech_keywords):
                        found_keywords.append(keyword)

            if found_keywords:
                unique_keywords = list(set(found_keywords))[:3]
                analysis_result.append(
                    f"âœ… **{standard}**: å·²æåŠ - {', '.join(unique_keywords)}"
                )
            else:
                missing_parts.append(f"âŒ **{standard}**: ç¼ºå°‘ç›¸é—œå…§å®¹")
                suggestions.append(f"å»ºè­°è£œå……{standard}çš„å…§å®¹")

        # ç”Ÿæˆå ±å‘Š
        report = f"""
ğŸ“Š **é—œéµå­—åˆ†æå ±å‘Š** (å›é€€æ–¹æ¡ˆ)

**æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹å…§å®¹**ï¼š
{user_message}

**è©•ä¼°çµæœ**ï¼š
{chr(10).join(analysis_result)}

{chr(10).join(missing_parts) if missing_parts else 'ğŸ‰ æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹çµæ§‹å®Œæ•´ï¼'}

**æ”¹é€²å»ºè­°**ï¼š
{chr(10).join([f"â€¢ {suggestion}" for suggestion in suggestions]) if suggestions else "â€¢ æ‚¨çš„è‡ªæˆ‘ä»‹ç´¹å·²ç¶“å¾ˆå®Œæ•´ï¼Œç¹¼çºŒä¿æŒï¼"}

**åƒè€ƒç¯„ä¾‹çµæ§‹**ï¼š
1. é–‹å ´ç°¡ä»‹ï¼šã€Œæ‚¨å¥½ï¼Œæˆ‘æ˜¯XXXï¼Œä¸€ä½æœ‰Xå¹´ç¶“é©—çš„XXXã€
2. å­¸ç¶“æ­·ï¼šã€Œæˆ‘ç•¢æ¥­æ–¼XXXï¼Œåœ¨XXXå…¬å¸æ“”ä»»XXXã€  
3. æŠ€èƒ½å¼·é …ï¼šã€Œæˆ‘ç†Ÿæ‚‰XXXæŠ€è¡“ï¼Œæ“…é•·XXXã€
4. ä»£è¡¨æˆæœï¼šã€Œæˆ‘æ›¾ç¶“XXXï¼Œæå‡äº†X%æ•ˆç‡ã€
5. è·ç¼ºé€£çµï¼šã€Œæˆ‘èªç‚ºé€™å€‹è·ä½èˆ‡æˆ‘çš„XXXç¶“é©—åŒ¹é…ã€
6. çµèªæœŸå¾…ï¼šã€ŒæœŸå¾…èƒ½ç‚ºè²´å…¬å¸è²¢ç»æˆ‘çš„å°ˆé•·ã€
        """

        return {
            "success": True,
            "result": report,
            "message": "é—œéµå­—åˆ†æå®Œæˆ (å›é€€æ–¹æ¡ˆ)",
        }
    except Exception as e:
        return {"success": False, "error": f"é—œéµå­—åˆ†æå¤±æ•—: {str(e)}"}


def generate_final_summary(user_message: str = "", interview_data: dict | None = None):
    """ç”Ÿæˆæœ€çµ‚é¢è©¦ç¸½çµå’Œå»ºè­°"""
    try:
        print(f"ğŸ“‹ ç”Ÿæˆæœ€çµ‚é¢è©¦ç¸½çµ")

        # æ”¶é›†å¯¦éš›çš„é¢è©¦æ•¸æ“š
        actual_data = _collect_actual_interview_data(interview_data)

        # åŸºæ–¼å¯¦éš›æ•¸æ“šç”Ÿæˆç¸½çµ
        return _generate_comprehensive_summary(actual_data)

    except Exception as e:
        return {"success": False, "error": f"ç”Ÿæˆæœ€çµ‚ç¸½çµå¤±æ•—: {str(e)}"}


def _collect_actual_interview_data(interview_data: dict | None = None):
    """æ”¶é›†å¯¦éš›çš„é¢è©¦æ•¸æ“š"""
    try:
        # æ”¶é›†è‡ªæˆ‘ä»‹ç´¹å…§å®¹
        intro_content = get_collected_intro("default_user")

        # åˆå§‹åŒ–æ•¸æ“šçµæ§‹
        actual_data = {
            "intro_content": intro_content,
            "intro_analysis": None,
            "questions_and_answers": [],
            "scores": [],
            "total_questions": 0,
            "average_score": 0,
        }

        # å¦‚æœæœ‰å‰ç«¯å‚³ä¾†çš„é¢è©¦æ•¸æ“šï¼Œä½¿ç”¨å®ƒ
        if interview_data and "chat_history" in interview_data:
            chat_history = interview_data["chat_history"]

            for chat in chat_history:
                stage = chat.get("stage", "")
                ai_response = chat.get("ai", "")
                user_message = chat.get("user", "")

                # æ”¶é›†è‡ªæˆ‘ä»‹ç´¹åˆ†æ
                if stage == "intro_analysis" and "è‡ªæˆ‘ä»‹ç´¹åˆ†æ" in ai_response:
                    actual_data["intro_analysis"] = ai_response

                # æ”¶é›†å•ç­”å°è©±å’Œè©•åˆ†
                elif stage == "questioning":
                    if "è«‹çµ¦æˆ‘å•é¡Œ" in user_message and "å•é¡Œï¼š" in ai_response:
                        # é€™æ˜¯ä¸€å€‹å•é¡Œ
                        actual_data["questions_and_answers"].append(
                            {"type": "question", "content": ai_response}
                        )
                    elif "è©•åˆ†ï¼š" in ai_response or "åˆ†æçµæœ" in ai_response:
                        # é€™æ˜¯ç­”æ¡ˆåˆ†æ
                        actual_data["questions_and_answers"].append(
                            {
                                "type": "answer_analysis",
                                "user_answer": user_message,
                                "analysis": ai_response,
                            }
                        )

                        # æå–è©•åˆ†
                        score = _extract_score_from_response(ai_response)
                        if score is not None:
                            actual_data["scores"].append(score)

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        actual_data["total_questions"] = len(
            [
                qa
                for qa in actual_data["questions_and_answers"]
                if qa["type"] == "question"
            ]
        )
        if actual_data["scores"]:
            actual_data["average_score"] = sum(actual_data["scores"]) / len(
                actual_data["scores"]
            )

        return actual_data

    except Exception as e:
        print(f"âŒ æ”¶é›†é¢è©¦æ•¸æ“šå¤±æ•—: {e}")
        return {
            "intro_content": "",
            "intro_analysis": None,
            "questions_and_answers": [],
            "scores": [],
            "total_questions": 0,
            "average_score": 0,
        }


def _extract_score_from_response(response: str):
    """å¾å›æ‡‰ä¸­æå–è©•åˆ†"""
    try:
        import re

        # å°‹æ‰¾è©•åˆ†æ¨¡å¼
        patterns = [r"è©•åˆ†ï¼š(\d+)", r"è©•åˆ†: (\d+)", r"Score: (\d+)", r"Scoreï¼š(\d+)"]

        for pattern in patterns:
            match = re.search(pattern, response)
            if match:
                return int(match.group(1))
        return None
    except:
        return None


def _generate_comprehensive_summary(actual_data: dict):
    """åŸºæ–¼å¯¦éš›æ•¸æ“šç”Ÿæˆç¶œåˆç¸½çµ"""
    try:
        # æ§‹å»ºç¸½çµå…§å®¹
        summary_parts = []

        # æ¨™é¡Œ
        summary_parts.append("ğŸ¯ **é¢è©¦ç¸½çµå ±å‘Š**\n")

        # è‡ªæˆ‘ä»‹ç´¹åˆ†æéƒ¨åˆ†
        if actual_data["intro_content"]:
            summary_parts.append("ğŸ“ **è‡ªæˆ‘ä»‹ç´¹è©•åƒ¹**ï¼š")
            if actual_data["intro_analysis"]:
                # æå–åˆ†æä¸­çš„é—œéµä¿¡æ¯
                intro_summary = _extract_intro_summary(actual_data["intro_analysis"])
                summary_parts.append(intro_summary)
            else:
                summary_parts.append("âœ… æ‚¨æä¾›äº†è‡ªæˆ‘ä»‹ç´¹å…§å®¹ï¼Œå±•ç¾äº†è‰¯å¥½çš„è¡¨é”èƒ½åŠ›ã€‚")
            summary_parts.append("")

        # é¢è©¦å•ç­”åˆ†æéƒ¨åˆ†
        if actual_data["questions_and_answers"]:
            summary_parts.append("ğŸ’¬ **é¢è©¦å•ç­”è¡¨ç¾**ï¼š")
            summary_parts.append(
                f"ğŸ“Š ç¸½å…±å›ç­”äº† {actual_data['total_questions']} å€‹å•é¡Œ"
            )

            if actual_data["scores"]:
                avg_score = actual_data["average_score"]
                summary_parts.append(f"ğŸ“ˆ å¹³å‡è©•åˆ†ï¼š{avg_score:.1f}/100")

                # åŸºæ–¼è©•åˆ†çµ¦å‡ºè©•åƒ¹
                if avg_score >= 90:
                    performance = "ğŸŒŸ å„ªç§€ - å›ç­”æº–ç¢ºæ·±å…¥ï¼Œå±•ç¾äº†æ‰å¯¦çš„å°ˆæ¥­èƒ½åŠ›"
                elif avg_score >= 80:
                    performance = "ğŸ‘ è‰¯å¥½ - å›ç­”åŸºæœ¬æ­£ç¢ºï¼Œå…·å‚™ç›¸é—œçŸ¥è­˜åŸºç¤"
                elif avg_score >= 70:
                    performance = "âœ… å°šå¯ - æœ‰ä¸€å®šç†è§£ï¼Œä½†éœ€è¦åŠ å¼·æ·±åº¦"
                else:
                    performance = "ğŸ“š éœ€è¦æ”¹é€² - å»ºè­°åŠ å¼·ç›¸é—œçŸ¥è­˜å­¸ç¿’"

                summary_parts.append(f"ğŸ¯ æ•´é«”è¡¨ç¾ï¼š{performance}")
            summary_parts.append("")

        # å…·é«”å»ºè­°éƒ¨åˆ†
        summary_parts.append("ğŸ’¡ **æ”¹é€²å»ºè­°**ï¼š")
        suggestions = _generate_specific_suggestions(actual_data)
        summary_parts.extend(suggestions)

        # åˆä½µæ‰€æœ‰éƒ¨åˆ†
        full_summary = "\n".join(summary_parts)

        return {
            "success": True,
            "result": full_summary,
            "message": "åŸºæ–¼å¯¦éš›é¢è©¦æ•¸æ“šç”Ÿæˆçš„ç¶œåˆç¸½çµ",
        }

    except Exception as e:
        print(f"âŒ ç”Ÿæˆç¶œåˆç¸½çµå¤±æ•—: {e}")
        # å›é€€åˆ°æ¨¡æ¿
        return _generate_template_summary()


def _extract_intro_summary(intro_analysis: str):
    """å¾è‡ªæˆ‘ä»‹ç´¹åˆ†æä¸­æå–é—œéµæ‘˜è¦"""
    try:
        # æå–è©•åˆ†å’Œä¸»è¦å»ºè­°
        lines = intro_analysis.split("\n")
        summary_points = []

        for line in lines:
            if "è©•åˆ†:" in line or "è©•åˆ†ï¼š" in line or "ç¸½åˆ†" in line:
                summary_points.append(f"ğŸ“Š {line.strip()}")
            elif line.strip().startswith("âœ…") and len(line.strip()) < 100:
                summary_points.append(line.strip())
            elif line.strip().startswith("âŒ") and len(line.strip()) < 100:
                summary_points.append(line.strip())

        if summary_points:
            return "\n".join(summary_points[:3])  # æœ€å¤š3å€‹è¦é»
        else:
            return "âœ… è‡ªæˆ‘ä»‹ç´¹å…§å®¹å·²æ”¶åˆ°ä¸¦åˆ†æï¼Œå±•ç¾äº†æ‚¨çš„èƒŒæ™¯å’Œèƒ½åŠ›ã€‚"
    except:
        return "âœ… è‡ªæˆ‘ä»‹ç´¹éšæ®µå·²å®Œæˆã€‚"


def _generate_specific_suggestions(actual_data: dict):
    """åŸºæ–¼å¯¦éš›æ•¸æ“šç”Ÿæˆå…·é«”å»ºè­°"""
    suggestions = []

    # åŸºæ–¼è‡ªæˆ‘ä»‹ç´¹çš„å»ºè­°
    if actual_data.get("intro_content"):
        if len(actual_data["intro_content"]) < 100:
            suggestions.append("ğŸ—£ï¸ è‡ªæˆ‘ä»‹ç´¹å¯ä»¥æ›´åŠ è©³ç´°ï¼ŒåŒ…å«æ›´å¤šå…·é«”çš„ç¶“é©—å’Œæˆæœ")
        else:
            suggestions.append("âœ… è‡ªæˆ‘ä»‹ç´¹å…§å®¹è±å¯Œï¼Œç¹¼çºŒä¿æŒé€™ç¨®è¡¨é”é¢¨æ ¼")

    # åŸºæ–¼è©•åˆ†çš„å»ºè­°
    if actual_data.get("scores") and actual_data.get("average_score"):
        avg_score = actual_data["average_score"]
        if avg_score < 80:
            suggestions.append("ğŸ“š å»ºè­°åŠ å¼·æŠ€è¡“çŸ¥è­˜çš„æ·±åº¦ï¼Œå¤šç·´ç¿’å…·é«”æ¡ˆä¾‹çš„è§£é‡‹")
            suggestions.append("ğŸ’­ å›ç­”æ™‚å¯ä»¥æä¾›æ›´å¤šå…·é«”çš„ä¾‹å­å’Œå¯¦éš›ç¶“é©—")
        else:
            suggestions.append("ğŸ¯ ä¿æŒè‰¯å¥½çš„å›ç­”å“è³ªï¼Œå¯ä»¥å˜—è©¦æ›´æ·±å…¥çš„æŠ€è¡“è¨è«–")

    # åŸºæ–¼å•é¡Œæ•¸é‡çš„å»ºè­°
    if actual_data.get("total_questions", 0) < 3:
        suggestions.append("â° å»ºè­°å®Œæˆæ›´å¤šé¢è©¦å•é¡Œï¼Œä»¥ç²å¾—æ›´å…¨é¢çš„ç·´ç¿’")

    # è‡³å°‘æä¾›3å€‹å»ºè­°ï¼Œä½¿ç”¨é è¨­å»ºè­°è£œå……
    default_suggestions = [
        "ğŸ“– å»ºè­°æº–å‚™æ›´å¤šæŠ€è¡“å•é¡Œçš„æ¨™æº–ç­”æ¡ˆ",
        "ğŸ¤ å¤šé€²è¡Œæ¨¡æ“¬é¢è©¦ï¼Œå¢åŠ å¯¦æˆ°ç¶“é©—",
        "ğŸ¯ ç¹¼çºŒç·´ç¿’é¢è©¦è¡¨é”ï¼Œä¿æŒè‡ªä¿¡å’Œæ¸…æ™°çš„æºé€š",
    ]

    # å¦‚æœå»ºè­°ä¸è¶³3å€‹ï¼Œå¾é è¨­å»ºè­°ä¸­è£œå……
    suggestion_index = 0
    while len(suggestions) < 3 and suggestion_index < len(default_suggestions):
        default_suggestion = default_suggestions[suggestion_index]
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰é¡ä¼¼çš„å»ºè­°ï¼ˆç°¡åŒ–æª¢æŸ¥é‚è¼¯ï¼‰
        is_duplicate = False
        for existing_suggestion in suggestions:
            # æª¢æŸ¥é—œéµè©æ˜¯å¦é‡è¤‡
            if any(keyword in existing_suggestion for keyword in ["ğŸ“–", "ğŸ¤", "ğŸ¯"]):
                if any(keyword in default_suggestion for keyword in ["ğŸ“–", "ğŸ¤", "ğŸ¯"]):
                    is_duplicate = True
                    break
        if not is_duplicate:
            suggestions.append(default_suggestion)
        suggestion_index += 1

    # ç‚ºæ‰€æœ‰å»ºè­°æ·»åŠ é€£çºŒç·¨è™Ÿ
    numbered_suggestions = []
    for i, suggestion in enumerate(suggestions, 1):
        numbered_suggestions.append(f"{i}. {suggestion}")

    return numbered_suggestions


def _generate_template_summary():
    """ç”ŸæˆåŸºæ–¼æ¨¡æ¿çš„ç¸½çµï¼ˆç•¶æ²’æœ‰å¯¦éš›æ•¸æ“šæ™‚ï¼‰"""
    summary = f"""
ğŸ¯ **é¢è©¦ç¸½çµå ±å‘Š**

**é¢è©¦å®Œæˆæƒ…æ³**ï¼š
âœ… è‡ªæˆ‘ä»‹ç´¹éšæ®µ - å·²å®Œæˆ
âœ… è‡ªæˆ‘ä»‹ç´¹åˆ†æ - å·²å®Œæˆ  
âœ… é¢è©¦å•ç­”éšæ®µ - å·²å®Œæˆ
âœ… æœ€çµ‚ç¸½çµ - å·²å®Œæˆ

**é‡è¦æé†’**ï¼š
âš ï¸ **æ³¨æ„**ï¼šæ­¤ç¸½çµåŸºæ–¼ç³»çµ±æ¨¡æ¿ç”Ÿæˆï¼Œç„¡æ³•åæ˜ æ‚¨çš„å¯¦éš›è¡¨ç¾ã€‚

**å»ºè­°æ”¹é€²**ï¼š
â€¢ ç³»çµ±éœ€è¦æ”¹é€²ä»¥è®€å–å’Œåˆ†æå¯¦éš›çš„é¢è©¦æ•¸æ“š
â€¢ å»ºè­°æ ¹æ“šçœŸå¯¦çš„è©•åˆ†å’Œè¡¨ç¾ç”Ÿæˆæº–ç¢ºçš„ç¸½çµ

**æŠ€è¡“æ”¹é€²å»ºè­°**ï¼š
1. ğŸ”§ ä¿®æ”¹ç³»çµ±ä»¥å‚³éå¯¦éš›é¢è©¦æ•¸æ“š
2. ğŸ“Š åˆ†æçœŸå¯¦çš„è©•åˆ†è¨˜éŒ„
3. ğŸ¯ æ ¹æ“šå¯¦éš›è¡¨ç¾ç”Ÿæˆæº–ç¢ºçš„è©•åƒ¹
4. ğŸ“ˆ æä¾›åŸºæ–¼æ•¸æ“šçš„æ”¹é€²å»ºè­°
    """

    return {
        "success": True,
        "result": summary,
        "message": "æœ€çµ‚ç¸½çµç”Ÿæˆå®Œæˆï¼ˆåŸºæ–¼æ¨¡æ¿ï¼‰",
    }


def _generate_data_based_summary(interview_data: dict):
    """åŸºæ–¼å¯¦éš›æ•¸æ“šç”Ÿæˆç¸½çµ"""
    try:
        # è§£æé¢è©¦æ•¸æ“š
        chat_history = interview_data.get("chat_history", [])

        # åˆ†æè©•åˆ†æ•¸æ“š
        scores = []
        total_questions = 0
        analysis_results = []

        for chat in chat_history:
            if chat.get("stage") == "questioning" and "ai" in chat:
                ai_response = chat["ai"]
                # æå–è©•åˆ†ä¿¡æ¯
                if "è©•åˆ†ï¼š" in ai_response or "Score:" in ai_response:
                    total_questions += 1
                    # å˜—è©¦æå–åˆ†æ•¸
                    score = _extract_score_from_response(ai_response)
                    if score is not None:
                        scores.append(score)
                        analysis_results.append(
                            {
                                "question": chat.get("user", ""),
                                "score": score,
                                "response": ai_response,
                            }
                        )

        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        if scores:
            average_score = sum(scores) / len(scores)
            min_score = min(scores)
            max_score = max(scores)

            # æ ¹æ“šå¹³å‡åˆ†æ•¸ç”Ÿæˆè©•åƒ¹
            if average_score >= 80:
                overall_rating = "å„ªç§€"
                performance_desc = "è¡¨ç¾å‡ºè‰²ï¼Œå›ç­”æº–ç¢ºä¸”å®Œæ•´"
            elif average_score >= 60:
                overall_rating = "è‰¯å¥½"
                performance_desc = "è¡¨ç¾è‰¯å¥½ï¼Œæœ‰æ”¹é€²ç©ºé–“"
            elif average_score >= 40:
                overall_rating = "ä¸­ç­‰"
                performance_desc = "è¡¨ç¾ä¸€èˆ¬ï¼Œéœ€è¦åŠ å¼·ç·´ç¿’"
            else:
                overall_rating = "éœ€è¦æ”¹é€²"
                performance_desc = "è¡¨ç¾è¼ƒå·®ï¼Œéœ€è¦å¤§é‡ç·´ç¿’"
        else:
            average_score = 0
            overall_rating = "ç„¡æ³•è©•ä¼°"
            performance_desc = "æ²’æœ‰è¶³å¤ çš„è©•åˆ†æ•¸æ“š"

        # ç”Ÿæˆç¸½çµ
        summary = f"""
ğŸ¯ **é¢è©¦ç¸½çµå ±å‘Š**

**é¢è©¦å®Œæˆæƒ…æ³**ï¼š
âœ… è‡ªæˆ‘ä»‹ç´¹éšæ®µ - å·²å®Œæˆ
âœ… è‡ªæˆ‘ä»‹ç´¹åˆ†æ - å·²å®Œæˆ  
âœ… é¢è©¦å•ç­”éšæ®µ - å·²å®Œæˆ ({total_questions} é¡Œ)
âœ… æœ€çµ‚ç¸½çµ - å·²å®Œæˆ

**å¯¦éš›è¡¨ç¾è©•ä¼°**ï¼š
â€¢ **ç¸½é¡Œæ•¸**: {total_questions} é¡Œ
â€¢ **å¹³å‡åˆ†æ•¸**: {average_score:.1f}/100
â€¢ **æœ€é«˜åˆ†æ•¸**: {max_score if scores else 'N/A'}/100
â€¢ **æœ€ä½åˆ†æ•¸**: {min_score if scores else 'N/A'}/100
â€¢ **æ•´é«”è©•ç´š**: {overall_rating}

**è¡¨ç¾åˆ†æ**ï¼š
{performance_desc}

**å…·é«”å»ºè­°**ï¼š
{_generate_specific_advice(average_score, scores)}

**ä¸‹æ¬¡é¢è©¦æº–å‚™é‡é»**ï¼š
1. ğŸ¯ åŠ å¼·æŠ€è¡“å•é¡Œçš„æº–å‚™å’Œç·´ç¿’
2. ğŸ“Š æé«˜å›ç­”çš„æº–ç¢ºæ€§å’Œå®Œæ•´æ€§
3. ğŸ” å¤šé€²è¡Œæ¨¡æ“¬é¢è©¦ç·´ç¿’
4. ğŸ’¡ å­¸ç¿’æ¨™æº–ç­”æ¡ˆçš„çµæ§‹å’Œè¦é»

**ç¸½è©•**: æ‚¨åœ¨æœ¬æ¬¡æ¨¡æ“¬é¢è©¦ä¸­çš„è¡¨ç¾ç‚º {overall_rating}ï¼Œå»ºè­°æ ¹æ“šä¸Šè¿°å»ºè­°é€²è¡Œæ”¹é€²ã€‚
        """

        return {
            "success": True,
            "result": summary,
            "message": "æœ€çµ‚ç¸½çµç”Ÿæˆå®Œæˆï¼ˆåŸºæ–¼å¯¦éš›æ•¸æ“šï¼‰",
        }

    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ•¸æ“šåŸºç¤ç¸½çµå¤±æ•—: {e}")
        return _generate_template_summary()


def _generate_specific_advice(average_score: float, scores: list) -> str:
    """æ ¹æ“šåˆ†æ•¸ç”Ÿæˆå…·é«”å»ºè­°"""
    if not scores:
        return "â€¢ å»ºè­°å¤šé€²è¡Œæ¨¡æ“¬é¢è©¦ç·´ç¿’ï¼Œæé«˜å›ç­”è³ªé‡"

    if average_score >= 80:
        return """â€¢ ä¿æŒå„ªç§€çš„è¡¨ç¾ï¼Œç¹¼çºŒæ·±åŒ–æŠ€è¡“çŸ¥è­˜
â€¢ å¯ä»¥å˜—è©¦æ›´å…·æŒ‘æˆ°æ€§çš„å•é¡Œ
â€¢ å»ºè­°åˆ†äº«æ‚¨çš„å­¸ç¿’æ–¹æ³•å’Œç¶“é©—"""
    elif average_score >= 60:
        return """â€¢ åŠ å¼·æŠ€è¡“å•é¡Œçš„æº–å‚™å’Œç·´ç¿’
â€¢ æé«˜å›ç­”çš„æº–ç¢ºæ€§å’Œå®Œæ•´æ€§
â€¢ å¤šå­¸ç¿’æ¨™æº–ç­”æ¡ˆçš„çµæ§‹å’Œè¦é»"""
    elif average_score >= 40:
        return """â€¢ éœ€è¦å¤§é‡ç·´ç¿’æŠ€è¡“å•é¡Œ
â€¢ åŠ å¼·åŸºç¤çŸ¥è­˜çš„å­¸ç¿’
â€¢ å»ºè­°åƒåŠ æ›´å¤šæ¨¡æ“¬é¢è©¦"""
    else:
        return """â€¢ éœ€è¦å¾åŸºç¤é–‹å§‹åŠ å¼·å­¸ç¿’
â€¢ å»ºè­°åƒåŠ åŸ¹è¨“èª²ç¨‹æˆ–å­¸ç¿’å°çµ„
â€¢ å¤šé€²è¡ŒåŸºç¤çŸ¥è­˜çš„ç·´ç¿’"""


def interview_system():
    """æ™ºèƒ½é¢è©¦ç³»çµ±ä¸» Agent"""
    return """
æ™ºèƒ½é¢è©¦ç³»çµ±å·²å•Ÿå‹•ï¼

å¯ç”¨åŠŸèƒ½ï¼š
1. ç²å–éš¨æ©Ÿé¢è©¦å•é¡Œ
2. åˆ†ææ‚¨çš„å›ç­”
3. æä¾›æ¨™æº–ç­”æ¡ˆ
4. ç”Ÿæˆé¢è©¦å ±å‘Š

è«‹å‘Šè¨´æˆ‘æ‚¨éœ€è¦ä»€éº¼å¹«åŠ©ï¼Ÿ
    """


# è¼”åŠ©å‡½æ•¸
def _categorize_question(question: str) -> str:
    """å°å•é¡Œé€²è¡Œåˆ†é¡"""
    categories = {
        "è‡ªæˆ‘ä»‹ç´¹": ["ä»‹ç´¹", "è‡ªå·±", "èƒŒæ™¯", "ç¶“æ­·"],
        "æŠ€è¡“èƒ½åŠ›": ["æŠ€è¡“", "æŠ€èƒ½", "ç¨‹å¼", "é–‹ç™¼", "ç¨‹å¼è¨­è¨ˆ"],
        "å°ˆæ¡ˆç¶“é©—": ["å°ˆæ¡ˆ", "ç¶“é©—", "å¯¦ä½œ", "ä½œå“"],
        "å•é¡Œè§£æ±º": ["å•é¡Œ", "è§£æ±º", "å›°é›£", "æŒ‘æˆ°"],
        "åœ˜éšŠåˆä½œ": ["åœ˜éšŠ", "åˆä½œ", "æºé€š", "å”ä½œ"],
        "å­¸ç¿’èƒ½åŠ›": ["å­¸ç¿’", "æˆé•·", "é€²æ­¥", "æ–°æŠ€è¡“"],
    }

    question_lower = question.lower()
    for category, keywords in categories.items():
        if any(keyword in question_lower for keyword in keywords):
            return category

    return "ä¸€èˆ¬å•é¡Œ"


def _assess_difficulty(question: str) -> str:
    """è©•ä¼°å•é¡Œé›£åº¦"""
    question_lower = question.lower()

    if len(question) < 50:
        return "ç°¡å–®"
    elif len(question) < 100:
        return "ä¸­ç­‰"
    else:
        return "å›°é›£"


# æ©‹æ¥å‡½æ•¸
def call_fast_agent_function(function_name, **kwargs):
    """èª¿ç”¨ Fast Agent åŠŸèƒ½"""
    try:
        if function_name == "get_question":
            result = get_question()
            # ç¢ºä¿è¿”å›çµ±ä¸€æ ¼å¼
            if isinstance(result, str):
                return {"success": True, "result": result}
            else:
                return result
        elif function_name == "analyze_answer":
            result = analyze_answer(**kwargs)
            return result  # analyze_answer ç¾åœ¨è¿”å›çµ±ä¸€æ ¼å¼
        elif function_name == "intro_collector":
            result = intro_collector(**kwargs)
            return result  # intro_collector è¿”å›çµ±ä¸€æ ¼å¼
        elif function_name == "analyze_intro":
            result = analyze_intro(**kwargs)
            return result  # analyze_intro è¿”å›çµ±ä¸€æ ¼å¼
        elif function_name == "generate_final_summary":
            result = generate_final_summary(**kwargs)
            return result  # generate_final_summary è¿”å›çµ±ä¸€æ ¼å¼
        elif function_name == "get_standard_answer":
            result = get_standard_answer(**kwargs)
            # ç¢ºä¿è¿”å›çµ±ä¸€æ ¼å¼
            if isinstance(result, str):
                return {"success": True, "result": result}
            else:
                return result
        elif function_name == "start_interview":
            result = start_interview()
            # ç¢ºä¿è¿”å›çµ±ä¸€æ ¼å¼
            if isinstance(result, str):
                return {"success": True, "result": result}
            else:
                return result
        elif function_name == "interview_system":
            result = interview_system()
            # ç¢ºä¿è¿”å›çµ±ä¸€æ ¼å¼
            if isinstance(result, str):
                return {"success": True, "result": result}
            else:
                return result
        else:
            return {
                "success": False,
                "error": f"Fast Agent å‡½æ•¸ {function_name} ä¸å­˜åœ¨",
            }
    except Exception as e:
        return {"success": False, "error": f"Fast Agent èª¿ç”¨å¤±æ•—: {str(e)}"}


if __name__ == "__main__":
    # æ¸¬è©¦æ©‹æ¥åŠŸèƒ½
    print("æ¸¬è©¦ Fast Agent æ©‹æ¥åŠŸèƒ½...")

    result = call_fast_agent_function("get_question")
    print(f"get_question çµæœ: {result}")

    result = call_fast_agent_function("interview_system")
    print(f"interview_system çµæœ: {result}")
